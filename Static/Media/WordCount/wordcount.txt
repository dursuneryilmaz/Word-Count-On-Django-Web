import findspark
findspark.init()

from pyspark import SparkConf
from pyspark import SparkContext

conf = SparkConf().setAppName("151805011_Dursun")
sc = SparkContext(conf=conf)

rdd = sc.textFile("151805011_Dursun_11.txt")
rdd.count()


words = rdd.flatMap(lambda line: line.split(" "))
wordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a,b:a+b)
wordCounts.saveAsTextFile("D:/WorkspaceSpark/output/")


for i in wordCounts.collect():
    print(i)